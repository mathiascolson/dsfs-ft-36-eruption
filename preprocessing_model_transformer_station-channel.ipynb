{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b865d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90b804f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIG GLOBAL\n",
    "# ============================================================\n",
    "\n",
    "file_path = r\"D:\\Formation_Data_Engineer\\Data_FullStack\\Data_Engineer_Full_Stack\\Projet_groupe\\pf_2020-03-30_filtered_downsampled.csv\"\n",
    "\n",
    "time_col = \"time\"\n",
    "amp_col = \"amplitude\"\n",
    "\n",
    "fs = 1/60      # échantillonnage 1/minute\n",
    "win = 10       # taille fenêtre (min)\n",
    "step = 10      # step fenêtres\n",
    "env_window = 20\n",
    "\n",
    "eruption_start = pd.to_datetime(\"2020-04-02T08:20:00Z\")\n",
    "eruption_end   = pd.to_datetime(\"2020-04-06T09:30:00Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "65b58138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FONCTIONS UTILITAIRES\n",
    "# ============================================================\n",
    "\n",
    "def type_component(ch):\n",
    "    ch = str(ch).upper()\n",
    "    return 0 if ch.endswith(\"Z\") else 1   # 0 = vertical, 1 = horizontal\n",
    "\n",
    "def shannon_entropy(segment, bins=50):\n",
    "    p, _ = np.histogram(segment, bins=bins, density=True)\n",
    "    p = p[p > 0]\n",
    "    if len(p)==0:\n",
    "        return 0.0\n",
    "    return -np.sum(p * np.log2(p))\n",
    "\n",
    "# def frequency_index(segment, fs):\n",
    "#     N = len(segment)\n",
    "#     freqs = np.fft.rfftfreq(N, d=1/fs)\n",
    "#     S = np.abs(np.fft.rfft(segment))**2\n",
    "\n",
    "#     low = (freqs>=1)&(freqs<=5.5)\n",
    "#     high = (freqs>=6)&(freqs<=16)\n",
    "\n",
    "#     E_low = S[low].sum()\n",
    "#     E_high = S[high].sum()\n",
    "\n",
    "#     if E_low == 0:\n",
    "#         return np.nan\n",
    "\n",
    "#     return np.log10(E_high/E_low) ==> à réintégrer si prise en compte de la Frequency Index\n",
    "\n",
    "def compute_delay_class(hours):\n",
    "    if pd.isna(hours): return 0\n",
    "    if hours <= 0: return 4\n",
    "    if hours <= 1: return 3\n",
    "    if hours <= 12: return 2\n",
    "    if hours <= 16: return 1\n",
    "    return 0\n",
    "\n",
    "def compute_delay_hours(t):\n",
    "    \"\"\"Return delay relative to eruption window.\"\"\"\n",
    "    if t > eruption_end:\n",
    "        return np.nan\n",
    "    if eruption_start <= t <= eruption_end:\n",
    "        return 0.0\n",
    "    # avant l'éruption → temps restant avant début\n",
    "    return (eruption_start - t).total_seconds()/3600.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1472e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. LECTURE + PREPROCESS LÉGER\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# standardisation nom colonnes\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "# conversion time\n",
    "df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "df = df.dropna(subset=[time_col])\n",
    "\n",
    "# composante numérique\n",
    "df[\"component_flag\"] = df[\"channel\"].apply(type_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b82b74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping channel -> composante\n",
    "component_map = {\n",
    "    \"EHZ\": 0, \"BHZ\": 0, \"HHZ\": 0,   # Vertical\n",
    "    \"EHE\": 1, \"EHN\": 1, \"BHE\": 1, \"BHN\": 1, \"HHE\": 1, \"HHN\": 1  # Horizontal\n",
    "}\n",
    "\n",
    "final_frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "808eba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Séparation par station / channel\n",
    "# ---------------------------\n",
    "station_channel_groups = {\n",
    "    (st, ch): g.sort_values(time_col).copy()\n",
    "    for (st, ch), g in df.groupby([\"station\", \"channel\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02cc1a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (st, ch), g in station_channel_groups.items():\n",
    "\n",
    "    sig = g[amp_col].astype(float).values\n",
    "    times = g[time_col].values\n",
    "    n = len(sig)\n",
    "\n",
    "    if n < win:\n",
    "        continue\n",
    "\n",
    "    rows = []\n",
    "    for i in range(0, n - win + 1, step):\n",
    "        seg = sig[i:i+win]\n",
    "        t_end = times[i+win-1]\n",
    "\n",
    "        SE  = shannon_entropy(seg)\n",
    "        K   = float(kurtosis(seg, fisher=True, bias=False))\n",
    "        #FI  = frequency_index(seg, fs) à réintégrer si prise en compte de la Frequency Index\n",
    "        std = float(np.std(seg))\n",
    "        mean = float(np.mean(seg))\n",
    "        med  = float(np.median(seg))\n",
    "        p90 = float(np.percentile(seg,90))\n",
    "        p10 = float(np.percentile(seg,10))\n",
    "        tens = p90 - p10\n",
    "\n",
    "        rows.append([t_end, SE, K, std, mean, med, p90, p10, tens]) #, FI à réintégrer si prise en compte de la Frequency Index\n",
    "\n",
    "    feat = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[\n",
    "            \"time\",\"SE\",\"Kurtosis\",\"std\",\"mean\",\"median\",\n",
    "            \"per90\",\"per10\",\"tension\"\n",
    "        ] #,\"FI\" à réintégrer si prise en compte de la Frequency Index\n",
    "    )\n",
    "\n",
    "    feat[\"station\"] = st\n",
    "    feat[\"channel\"] = ch\n",
    "\n",
    "    # -------- enveloppe (par DF isolé) --------\n",
    "    for col in [\"SE\",\"Kurtosis\",\"std\",\"mean\",\"median\",\"per90\",\"per10\",\"tension\"]: #,\"FI\" à réintégrer si prise en compte de la Frequency Index\n",
    "        feat[col+\"_env\"] = feat[col].rolling(env_window, min_periods=1).median()\n",
    "\n",
    "    # -------- delay + classe --------\n",
    "    feat[\"time\"] = feat[\"time\"].dt.tz_localize(\"UTC\").dt.tz_convert(\"UTC\")\n",
    "    feat[\"delay_hours\"] = feat[\"time\"].apply(compute_delay_hours)\n",
    "    feat[\"label\"] = feat[\"delay_hours\"].apply(compute_delay_class).astype(int)\n",
    "\n",
    "    # -------- tag composante --------\n",
    "    feat[\"component_flag\"] = component_map.get(ch, -1)\n",
    "\n",
    "    final_frames.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33f56840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Concat final\n",
    "# -----------------------------\n",
    "final_df = pd.concat(final_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0bf46112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# Encodage\n",
    "# ---------------------------\n",
    "# Colonnes numériques à garder\n",
    "numeric_features = [\"component_flag\",\"SE\",\"Kurtosis\",\"std\",\"mean\",\"median\",\"per90\",\"per10\",\"tension\",\n",
    "                    \"SE_env\",\"Kurt_env\",\"std_env\",\n",
    "                    \"year\",\"month\",\"day\",\"hour\",\"minute\"] #,\"FI\",\"FI_env\" à réintégrer si prise en compte de la Frequency Index\n",
    "\n",
    "# garder uniquement celles existantes\n",
    "numeric_features = [c for c in numeric_features if c in final_df.columns]\n",
    "\n",
    "# Colonnes catégorielles à encoder : station\n",
    "categorical_candidates = [c for c in final_df if c.lower() in (\"station\")]\n",
    "\n",
    "\n",
    "# Build preprocess pipeline\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"infrequent_if_exist\", sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_candidates)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Remplir NaN numériques par median avant scaler\n",
    "final_df[numeric_features] = final_df[numeric_features].fillna(final_df[numeric_features].median())\n",
    "\n",
    "# Remplir catégoriques na par 'unk'\n",
    "for c in categorical_candidates:\n",
    "    final_df[c] = final_df[c].fillna(\"unk\")\n",
    "\n",
    "\n",
    "X_num = final_df[numeric_features]\n",
    "X_cat = final_df[categorical_candidates]\n",
    "\n",
    "X_all= pd.concat([X_num,X_cat],axis=1)\n",
    "X_all_transformed = preprocessor.fit_transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e83723d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 10. Construction des sequences (sliding) pour le modèle\n",
    "# ---------------------------\n",
    "# On construit sequences non chevauchantes (ou chevauchantes selon step_sequence)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 64\n",
    "seq_length = 60       # longueur des séquences pour le modèle (en minutes)\n",
    "\n",
    "step_seq = 1  # si 1 -> séquences glissantes à chaque point; si seq_length -> non chevauchées\n",
    "X = X_all_transformed\n",
    "y = final_df[\"label\"].values\n",
    "T = len(X)\n",
    "\n",
    "seqs = []\n",
    "labels = []\n",
    "times_seq = []\n",
    "\n",
    "for i in range(0, T - seq_length, step_seq):\n",
    "    seq = X[i:i+seq_length]\n",
    "    # label associé au temps de fin de séquence (alignement)\n",
    "    lab = y[i+seq_length-1]\n",
    "    seqs.append(seq)\n",
    "    labels.append(lab)\n",
    "    times_seq.append(final_df.index[i+seq_length-1])\n",
    "\n",
    "X_seq = np.stack(seqs).astype(np.float32)            # shape (N_seq, seq_length, n_features)\n",
    "y_seq = np.array(labels)          # shape (N_seq,)\n",
    "\n",
    "# ---------------------------\n",
    "# 11. Train/Val/Test split temporel\n",
    "# ---------------------------\n",
    "N = len(X_seq)\n",
    "train_frac = 0.7\n",
    "val_frac = 0.15\n",
    "test_frac = 0.15\n",
    "\n",
    "i_train_end = int(N * train_frac)\n",
    "i_val_end   = int(N * (train_frac + val_frac))\n",
    "\n",
    "X_train = X_seq[:i_train_end]\n",
    "y_train = y_seq[:i_train_end]\n",
    "X_val   = X_seq[i_train_end:i_val_end]\n",
    "y_val   = y_seq[i_train_end:i_val_end]\n",
    "X_test  = X_seq[i_val_end:]\n",
    "y_test  = y_seq[i_val_end:]\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_val_t   = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_t   = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "X_test_t  = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_t  = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "val_ds   = TensorDataset(X_val_t, y_val_t)\n",
    "test_ds  = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d8d5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
